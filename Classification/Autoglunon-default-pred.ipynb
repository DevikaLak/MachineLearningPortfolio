{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ee4649-e979-41ed-acc5-3efeefb11a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -q -U 'sagemaker>=2.126.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3039a04-5d76-4b68-a30f-e38851b1b871",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting autogluon.tabular[all]==0.7.0\n",
      "  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.timeseries[all]==0.7.0\n",
      "  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 kB\u001b[0m \u001b[31m290.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.core[all]==0.7.0\n",
      "  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.3/218.3 kB\u001b[0m \u001b[31m325.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.features==0.7.0\n",
      "  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m251.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.multimodal==0.7.0\n",
      "  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m363.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx<3.0,>=2.3\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m302.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<1.12,>=1.5.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (1.8.1)\n",
      "Requirement already satisfied: pandas<1.6,>=1.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (1.4.4)\n",
      "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (1.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (2.28.1)\n",
      "Collecting autogluon.common==0.7.0\n",
      "  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m175.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: boto3<2,>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (1.26.71)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (4.63.2)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.core[all]==0.7.0->autogluon) (3.5.3)\n",
      "Collecting ray<2.3,>=2.2\n",
      "  Downloading ray-2.2.0-cp39-cp39-manylinux2014_x86_64.whl (57.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting hyperopt<0.2.8,>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m380.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (3.8.1)\n",
      "Collecting transformers<4.27.0,>=4.23.0\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m216.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonschema<4.18,>=4.14\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m243.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision<0.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (0.14.1)\n",
      "Collecting openmim<0.4.0,>0.1.5\n",
      "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m220.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-metric-learning<2.0,>=1.3.0\n",
      "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m222.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m334.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Pillow<9.6,>=9.3\n",
      "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m286.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (3.1.2)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (1.3)\n",
      "Collecting seqeval<1.3.0,>=1.2.2\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m206.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torchmetrics<0.9.0,>=0.8.0\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m349.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<3,>=2.9\n",
      "  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m208.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting timm<0.7.0,>=0.6.12\n",
      "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m383.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning<1.10.0,>=1.9.0\n",
      "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m371.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytesseract<0.3.11,>=0.3.9\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (0.7.1)\n",
      "Requirement already satisfied: torch<1.14,>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.multimodal==0.7.0->autogluon) (1.13.1)\n",
      "Collecting evaluate<0.4.0,>=0.2.2\n",
      "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m250.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4\n",
      "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
      "Collecting sentencepiece<0.2.0,>=0.1.95\n",
      "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m368.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.3.0,>=2.1.1\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m258.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fairscale<0.4.14,>=0.4.5\n",
      "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m354.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate<0.17,>=0.9\n",
      "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m321.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm<3.4,>=3.3\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m336.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xgboost<1.8,>=1.6\n",
      "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m233.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting catboost<1.2,>=1.0\n",
      "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m180.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastai<2.8,>=2.3.1\n",
      "  Downloading fastai-2.7.12-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m340.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting statsforecast<1.5,>=1.4.0\n",
      "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ujson<6,>=5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (5.7.0)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (0.13.5)\n",
      "Collecting gluonts<0.13,>=0.12.0\n",
      "  Downloading gluonts-0.12.6-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m313.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib<2,>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.2.0)\n",
      "Collecting sktime<0.16,>=0.14\n",
      "  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tbats<2,>=1.1\n",
      "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m212.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pmdarima<1.9,>=1.8.2\n",
      "  Downloading pmdarima-1.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (5.9.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (65.6.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (21.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.71 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon) (1.29.71)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (1.16.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m183.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (5.11.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m349.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.7.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m326.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (0.70.14)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (0.3.6)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m362.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (2022.11.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.3)\n",
      "Requirement already satisfied: spacy<4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.4.4)\n",
      "Collecting fastcore<1.6,>=1.5.29\n",
      "  Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m179.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (22.3.1)\n",
      "Requirement already satisfied: pydantic~=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (1.10.4)\n",
      "Requirement already satisfied: toolz~=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (4.4.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.18.2)\n",
      "Requirement already satisfied: cloudpickle in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (2.2.0)\n",
      "Requirement already satisfied: py4j in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.10.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.7.0->autogluon) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.7.0->autogluon) (0.38.4)\n",
      "Collecting gdown>=4.0.0\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (2022.10.31)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m292.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.4.3)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.9.0)\n",
      "Collecting model-index\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.3.4-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m338.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2022.7)\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (0.29.33)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (1.26.8)\n",
      "Collecting lightning-utilities>=0.6.0.post0\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting virtualenv>=20.0.24\n",
      "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m228.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ray<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.0.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ray<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.6.0)\n",
      "Requirement already satisfied: aiosignal in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ray<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.3.1)\n",
      "Collecting grpcio>=1.32.0\n",
      "  Downloading grpcio-1.53.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m283.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ray<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.20.2)\n",
      "Requirement already satisfied: frozenlist in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ray<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.3.3)\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m289.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2.1.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2.16.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.7.0->autogluon) (3.1.0)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numba>=0.55 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.56.4)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from statsmodels<0.14,>=0.13.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.5.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m260.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m356.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m294.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.2.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m194.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m309.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyDeprecate==0.3.*\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m213.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (4.38.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (10.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from deprecated>=1.2.13->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.11.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m328.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (4.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (4.13.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from numba>=0.55->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.39.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (5.2.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.11)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (8.1.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.4.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.8)\n",
      "Collecting distlib<1,>=0.3.6\n",
      "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m364.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (2.6.2)\n",
      "Collecting ordered-set\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (8.1.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.14.0)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m244.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.11.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m307.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (2.3.2.post1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (1.7.1)\n",
      "Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=33bdf2c4914b37635d381b4a04115852359f8d721781eadcbfe96609c515a686\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1t9so_u2/wheels/43/a4/fc/df441e25fce12062aae20587ed4214d6ab41b39d0ca9182c89\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=cabeebbdf89477716ae440e777e53143a56d87f5e46f4ec56bf84a2a9acba87e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1t9so_u2/wheels/a7/72/3e/7d4bb4df2f34e8a15d0d764bb98e7ca19a765483710646a8b3\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=2508091fdef10921b0fadd2c9f2d2bd696f71b791bb017c4583b4bceb583a4a4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1t9so_u2/wheels/9c/d6/00/1ccfd5a7466a94774e00022683d4b028836032dfb85007822b\n",
      "Successfully built fairscale antlr4-python3-runtime seqeval\n",
      "Installing collected packages: tokenizers, tensorboard-plugin-wit, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, tensorboard-data-server, pyDeprecate, pyasn1-modules, Pillow, ordered-set, omegaconf, oauthlib, nptyping, networkx, mdurl, jsonschema, grpcio, graphviz, deprecated, cachetools, absl-py, xgboost, torchmetrics, tensorboardX, responses, requests-oauthlib, ray, pytesseract, markdown-it-py, markdown, lightning-utilities, hyperopt, huggingface-hub, google-auth, fastcore, fairscale, accelerate, transformers, timm, seqeval, rich, pytorch-metric-learning, model-index, lightgbm, google-auth-oauthlib, gluonts, gdown, fastdownload, catboost, tensorboard, statsforecast, sktime, pytorch-lightning, pmdarima, openmim, nlpaug, datasets, tbats, fastai, evaluate, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.0\n",
      "    Uninstalling networkx-3.0:\n",
      "      Successfully uninstalled networkx-3.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 3.2.0\n",
      "    Uninstalling jsonschema-3.2.0:\n",
      "      Successfully uninstalled jsonschema-3.2.0\n",
      "  Attempting uninstall: fastcore\n",
      "    Found existing installation: fastcore 1.5.26\n",
      "    Uninstalling fastcore-1.5.26:\n",
      "      Successfully uninstalled fastcore-1.5.26\n",
      "  Attempting uninstall: fastai\n",
      "    Found existing installation: fastai 2.1.10\n",
      "    Uninstalling fastai-2.1.10:\n",
      "      Successfully uninstalled fastai-2.1.10\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.3.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.6 which is incompatible.\n",
      "jupyter-events 0.6.0 requires pyyaml>=6.0, but you have pyyaml 5.4.1 which is incompatible.\n",
      "docker-compose 1.29.2 requires jsonschema<4,>=2.5.1, but you have jsonschema 4.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-9.5.0 absl-py-1.4.0 accelerate-0.16.0 antlr4-python3-runtime-4.9.3 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 cachetools-5.3.0 catboost-1.1.1 datasets-2.11.0 deprecated-1.2.13 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 fastai-2.7.12 fastcore-1.5.29 fastdownload-0.0.7 gdown-4.7.1 gluonts-0.12.6 google-auth-2.17.3 google-auth-oauthlib-1.0.0 graphviz-0.20.1 grpcio-1.53.0 huggingface-hub-0.13.4 hyperopt-0.2.7 jsonschema-4.17.3 lightgbm-3.3.5 lightning-utilities-0.8.0 markdown-3.4.3 markdown-it-py-2.2.0 mdurl-0.1.2 model-index-0.1.11 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 oauthlib-3.2.2 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 requests-oauthlib-1.3.1 responses-0.18.0 rich-13.3.4 sentencepiece-0.1.98 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.2 tensorboard-2.12.2 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torchmetrics-0.8.2 transformers-4.26.1 virtualenv-20.21.0 xgboost-1.7.5 xxhash-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c52cba-6896-4a3b-bca1-78e8a5fd1118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "from sagemaker import utils\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0991dabb-413b-49f9-a018-81c6f2902084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper wrappers\n",
    "from ag_model import (\n",
    "    AutoGluonSagemakerEstimator,\n",
    "    AutoGluonNonRepackInferenceModel,\n",
    "    AutoGluonSagemakerInferenceModel,\n",
    "    AutoGluonRealtimePredictor,\n",
    ")\n",
    "\n",
    "# Sagemaker variables \n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session._region_name\n",
    "\n",
    "bucket = \"mle-capstone\"\n",
    "s3_prefix = f\"{utils.sagemaker_timestamp()}\"\n",
    "s3_data_prefix = \"final-data/Final-Capstone-Data.zip\"\n",
    "output_path = f\"s3://{bucket}/{s3_prefix}/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03156201-b217-41b0-8f69-a3fb19f96796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Command to download data from S3 (This command needs to be executed once)\n",
    "session.download_data(path=\"data\", bucket=bucket, key_prefix=s3_data_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c8efd27-56f3-470d-bae2-129bc53bf1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/Final-Capstone-Data.zip\n",
      "   creating: Final-Capstone-Data/\n",
      "  inflating: Final-Capstone-Data/valid.csv  \n",
      "  inflating: Final-Capstone-Data/test.csv  \n",
      "  inflating: Final-Capstone-Data/train.csv  \n"
     ]
    }
   ],
   "source": [
    "# Command to unzip the data (This command needs to be executed once)\n",
    "!unzip -o data/Final-Capstone-Data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e336c0-20ec-4d7e-980a-ee9f68cb3877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training job Estimator\n",
    "ag = AutoGluonSagemakerEstimator(\n",
    "    role=role,\n",
    "    entry_point=\"scripts/training_script.py\",\n",
    "    region=region,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"0.7\",\n",
    "    py_version=\"py39\",\n",
    "    base_job_name=\"autogluon-train\",\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf8a9da8-2ba1-4e9f-8d53-c154d8db634b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: test-autogluon-image-1681329605-8167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 20:00:09 Starting - Starting the training job...\n",
      "2023-04-12 20:00:24 Starting - Preparing the instances for training...\n",
      "2023-04-12 20:01:14 Downloading - Downloading input data...\n",
      "2023-04-12 20:01:34 Training - Downloading the training image.........\n",
      "2023-04-12 20:03:05 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:33,954 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:33,956 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:33,958 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:33,968 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:33,970 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,248 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,251 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,264 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,266 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,279 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,281 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:34,292 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"serving\": \"/opt/ml/input/data/serving\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"valid\": \"/opt/ml/input/data/valid\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"serving\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"test-autogluon-image-1681329605-8167\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681329605-8167/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training_script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"serving\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"serving\",\"test\",\"train\",\"valid\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681329605-8167/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"serving\":\"/opt/ml/input/data/serving\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"valid\":\"/opt/ml/input/data/valid\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"serving\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"test-autogluon-image-1681329605-8167\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681329605-8167/source/sourcedir.tar.gz\",\"module_name\":\"training_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_SERVING=/opt/ml/input/data/serving\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALID=/opt/ml/input/data/valid\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 training_script.py\u001b[0m\n",
      "\u001b[34m2023-04-12 20:03:35,169 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mStarting AG\u001b[0m\n",
      "\u001b[34mArgs: Namespace(output_data_dir='/opt/ml/output/data', model_dir='/opt/ml/model', n_gpus='0', train_dir='/opt/ml/input/data/train', valid_dir='/opt/ml/input/data/valid', test_dir='/opt/ml/input/data/test', ag_config='/opt/ml/input/data/config', serving_script='/opt/ml/input/data/serving')\u001b[0m\n",
      "\u001b[34mUsing config-med.yaml\u001b[0m\n",
      "\u001b[34mRunning training job with the config:\u001b[0m\n",
      "\u001b[34m{'ag_fit_args':\u001b[0m\n",
      "\u001b[34m{'num_bag_folds': 2,\n",
      "                 'num_bag_sets': 1,\n",
      "                 'num_stack_levels'\u001b[0m\n",
      "\u001b[34m: 0,\n",
      "                 'presets': 'best_quality',\n",
      "                 'time_limit':\u001b[0m\n",
      "\u001b[34m600,\n",
      "                 'use_bag_holdout': True},\n",
      " 'ag_predictor_args': {'eval_metric': 'roc_auc',\n",
      "                       'label': 'target',\n",
      "                       'learner_kwargs': {'ignored_columns': [\u001b[0m\n",
      "\u001b[34m'customer_ID',\n",
      "                                                              'S_2']},\n",
      "                       'problem_type': 'binary'},\n",
      " 'feature_importance': False,\n",
      " 'leaderboard': True,\n",
      " 'num_gpus': 0,\n",
      " 'output_prediction_format': 'csv'}\u001b[0m\n",
      "\u001b[34mUsing train.csv\u001b[0m\n",
      "\u001b[34mUsing valid.csv\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mPresets specified: ['best_quality']\u001b[0m\n",
      "\u001b[34mStack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=2, num_bag_sets=1\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ... Time limit = 600s\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.7.0\u001b[0m\n",
      "\u001b[34mPython Version:     3.9.16\u001b[0m\n",
      "\u001b[34mOperating System:   Linux\u001b[0m\n",
      "\u001b[34mPlatform Machine:   x86_64\u001b[0m\n",
      "\u001b[34mPlatform Version:   #1 SMP Tue Feb 14 21:50:23 UTC 2023\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    91000\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 46\u001b[0m\n",
      "\u001b[34mTuning Data Rows:    14000\u001b[0m\n",
      "\u001b[34mTuning Data Columns: 46\u001b[0m\n",
      "\u001b[34mLabel Column: target\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mSelected class <--> label mapping:  class 1 = 1, class 0 = 0\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mDropping user-specified ignored columns: ['customer_ID', 'S_2']\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34mAvailable Memory:                    31284.42 MB\u001b[0m\n",
      "\u001b[34mTrain Data (Original)  Memory Usage: 36.96 MB (0.1% of available memory)\u001b[0m\n",
      "\u001b[34mInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34mStage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34mNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\u001b[0m\n",
      "\u001b[34mStage 2 Generators:\u001b[0m\n",
      "\u001b[34mFitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34mStage 3 Generators:\u001b[0m\n",
      "\u001b[34mFitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34mStage 4 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34mTypes of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m('float', []) : 31 | ['CID_month', 'R_1', 'B_3', 'D_45', 'B_9', ...]\u001b[0m\n",
      "\u001b[34m('int', [])   : 13 | ['D_59', 'D_64', 'S_15', 'D_82', 'B_30', ...]\u001b[0m\n",
      "\u001b[34mTypes of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m('float', [])     : 31 | ['CID_month', 'R_1', 'B_3', 'D_45', 'B_9', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', [])       : 12 | ['D_59', 'D_64', 'S_15', 'D_82', 'B_30', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', ['bool']) :  1 | ['B_31']\u001b[0m\n",
      "\u001b[34m#0110.6s = Fit runtime\u001b[0m\n",
      "\u001b[34m44 features in original data used to generate 44 features in processed data.\u001b[0m\n",
      "\u001b[34mTrain Data (Processed) Memory Usage: 36.23 MB (0.1% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.64s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\u001b[0m\n",
      "\u001b[34m#011This metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\u001b[0m\n",
      "\u001b[34m#011To change this, specify the eval_metric parameter of Predictor()\u001b[0m\n",
      "\u001b[34muse_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\u001b[0m\n",
      "\u001b[34mFitting 13 L1 models ...\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 599.36s of the 599.36s of remaining time.\u001b[0m\n",
      "\u001b[34m0.8362#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.2s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m9.36s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsDist_BAG_L1 ... Training model for up to 587.16s of the 587.16s of remaining time.\u001b[0m\n",
      "\u001b[34m0.8365#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m0.21s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m9.45s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMXT_BAG_L1 ... Training model for up to 575.76s of the 575.76s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m0.9178#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01153.71s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#01116.27s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBM_BAG_L1 ... Training model for up to 504.0s of the 504.0s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m0.9185#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01145.68s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m8.4s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestGini_BAG_L1 ... Training model for up to 449.15s of the 449.15s of remaining time.\u001b[0m\n",
      "\u001b[34m0.9174#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01129.81s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m4.17s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestEntr_BAG_L1 ... Training model for up to 414.06s of the 414.06s of remaining time.\u001b[0m\n",
      "\u001b[34m0.9193#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01133.61s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m4.07s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost_BAG_L1 ... Training model for up to 375.36s of the 375.36s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m0.9156#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#011192.16s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.25s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 180.71s of the 180.71s of remaining time.\u001b[0m\n",
      "\u001b[34m0.9164#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0115.61s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m4.25s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 169.2s of the 169.2s of remaining time.\u001b[0m\n",
      "\u001b[34m0.9172#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0115.43s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m4.54s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 157.63s of the 157.63s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m[2023-04-12 20:12:17.580 algo-1:46 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-04-12 20:12:17.612 algo-1:46 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m0.8936#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01174.92s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m1.19s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost_BAG_L1 ... Training model for up to 79.13s of the 79.13s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m0.9195#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01163.37s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.81s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 12.99s of the 12.99s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m0.9172#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01110.48s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.8s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the -0.35s of remaining time.\u001b[0m\n",
      "\u001b[34m0.9236#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0112.59s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 602.99s ... Best model: \"WeightedEnsemble_L2\"\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34mUsing test.csv\u001b[0m\n",
      "\u001b[34mLoaded data from: /opt/ml/input/data/test/test.csv | Columns = 47 / 47 | Rows = 6000 -> 6000\u001b[0m\n",
      "\u001b[34mmodel  score_test  score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\u001b[0m\n",
      "\u001b[34m0       WeightedEnsemble_L2    0.926551   0.923608        4.107594      27.040528  196.565640                 0.004968                0.002330           2.590427            2       True         13\u001b[0m\n",
      "\u001b[34m1            XGBoost_BAG_L1    0.925854   0.919466        0.119128       0.807682   63.369500                 0.119128                0.807682          63.369500            1       True         11\u001b[0m\n",
      "\u001b[34m2           LightGBM_BAG_L1    0.922136   0.918469        1.240256       8.401661   45.676009                 1.240256                8.401661          45.676009            1       True          4\u001b[0m\n",
      "\u001b[34m3         LightGBMXT_BAG_L1    0.921918   0.917791        1.912325      16.272626   53.713734                 1.912325               16.272626          53.713734            1       True          3\u001b[0m\n",
      "\u001b[34m4           CatBoost_BAG_L1    0.920886   0.915619        0.054096       0.252894  192.159055                 0.054096                0.252894         192.159055            1       True          7\u001b[0m\n",
      "\u001b[34m5   RandomForestEntr_BAG_L1    0.920549   0.919312        0.476655       4.073381   33.606960                 0.476655                4.073381          33.606960            1       True          6\u001b[0m\n",
      "\u001b[34m6     NeuralNetTorch_BAG_L1    0.918949   0.917232        0.162580       0.798352   10.475005                 0.162580                0.798352          10.475005            1       True         12\u001b[0m\n",
      "\u001b[34m7   RandomForestGini_BAG_L1    0.918880   0.917411        0.521979       4.172811   29.813052                 0.521979                4.172811          29.813052            1       True          5\u001b[0m\n",
      "\u001b[34m8     ExtraTreesEntr_BAG_L1    0.918226   0.917158        0.798731       4.537413    5.428264                 0.798731                4.537413           5.428264            1       True          9\u001b[0m\n",
      "\u001b[34m9     ExtraTreesGini_BAG_L1    0.916705   0.916439        0.783296       4.246898    5.606423                 0.783296                4.246898           5.606423            1       True          8\u001b[0m\n",
      "\u001b[34m10   NeuralNetFastAI_BAG_L1    0.899065   0.893578        0.205287       1.189221   74.923853                 0.205287                1.189221          74.923853            1       True         10\u001b[0m\n",
      "\u001b[34m11    KNeighborsUnif_BAG_L1    0.839027   0.836201        0.831545       9.364735    0.200778                 0.831545                9.364735           0.200778            1       True          1\u001b[0m\n",
      "\u001b[34m12    KNeighborsDist_BAG_L1    0.838427   0.836499        0.705422       9.445793    0.208828                 0.705422                9.445793           0.208828            1       True          2\u001b[0m\n",
      "\u001b[34mSaving serving script\u001b[0m\n",
      "\u001b[34mUsing inference_script.py\u001b[0m\n",
      "\u001b[34m2023-04-12 20:13:55,229 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-04-12 20:13:55,229 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-04-12 20:13:55,230 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-04-12 20:13:59 Uploading - Uploading generated training model\n",
      "2023-04-12 20:16:25 Completed - Training job completed\n",
      "Training seconds: 911\n",
      "Billable seconds: 911\n"
     ]
    }
   ],
   "source": [
    "train_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"Final-Capstone-Data\", \"train.csv\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "valid_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"Final-Capstone-Data\", \"valid.csv\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "eval_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"Final-Capstone-Data\", \"test.csv\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-med.yaml\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "inference_script = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"scripts\", \"inference_script.py\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "\n",
    "job_name = utils.unique_name_from_base(\"test-autogluon-image\")\n",
    "ag.fit(\n",
    "    {\n",
    "        \"config\": config_input,\n",
    "        \"train\": train_input,\n",
    "        \"valid\": valid_input,\n",
    "        \"test\": eval_input,\n",
    "        \"serving\": inference_script\n",
    "    },\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcce4e-46f4-4767-a180-77b517ecf2b4",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e4ebb13-e57c-4c2c-bc5f-b9eb810f3252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681329605-8167/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Download the trained model saved in S3 (To be executed once)\n",
    "!aws s3 cp {ag.model_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afc97322-9c44-47b6-8ce3-883c8f67dc87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 406665479 Apr 12 20:16 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -alF model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6cda14e-f465-4a4b-a6e3-3190b906dd27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the latest trained model to a desired path in S3\n",
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"autogluon-serving-trained-model\")\n",
    "\n",
    "model_data = session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed0ddbae-99cd-4449-8a06-6855bdca806c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure for deployment and inferencing\n",
    "instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "model = AutoGluonNonRepackInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.7\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=instance_type,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"inference_script.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cdc1906-c4b8-422a-9208-b651b3ca27e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "model.deploy(initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9548eb-01c9-4216-97e6-16cde8b76cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autogluon-inference-2023-04-13-00-11-13-621'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print deployed latest endpoint details\n",
    "model.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7067fe8-9f9f-4ab7-89eb-31da25d15c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a predictor for testing without Lambda\n",
    "predictor = AutoGluonRealtimePredictor(model.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec2e3a97-f7a8-407c-8a39-4f5d0c54b66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Test data\n",
    "df_test = pd.read_csv(\"Final-Capstone-Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3ec014d-68ba-4aa9-bfad-b27f2ec8e77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on test data by removing columns not required\n",
    "preds = predictor.predict(df_test.drop(columns=[\"customer_ID\", \"S_2\", \"target\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41d6e026-2130-4ac3-81db-5fe13981b995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred  actual\n",
       "0     1       1\n",
       "1     1       1\n",
       "2     0       0\n",
       "3     1       1\n",
       "4     1       1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine predicted and actual values in same Dataframe\n",
    "p = preds[[\"pred\"]]\n",
    "p = p.join(df_test[\"target\"]).rename(columns={\"target\": \"actual\"})\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c65e91b2-3fa0-4608-8470-7673873a6251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982/6000 are correct\n"
     ]
    }
   ],
   "source": [
    "# Print the accurate prediction count\n",
    "print(f\"{(p.pred==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9e4bc-1536-41cc-b187-bb79413941f8",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879c3ccd-c3bf-4127-a420-2466da03f9b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: test-autogluon-image-1681570642-16bb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-15 14:57:23 Starting - Starting the training job...\n",
      "2023-04-15 14:57:38 Starting - Preparing the instances for training...\n",
      "2023-04-15 14:58:18 Downloading - Downloading input data...\n",
      "2023-04-15 14:58:38 Training - Downloading the training image......\n",
      "2023-04-15 14:59:49 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,563 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,565 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,567 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,577 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,579 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,814 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,816 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,829 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,831 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,844 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,846 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:11,856 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"serving\": \"/opt/ml/input/data/serving\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"valid\": \"/opt/ml/input/data/valid\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"serving\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"test-autogluon-image-1681570642-16bb\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681570642-16bb/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"training_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training_script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"serving\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"serving\",\"test\",\"train\",\"valid\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681570642-16bb/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"serving\":\"/opt/ml/input/data/serving\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"valid\":\"/opt/ml/input/data/valid\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"serving\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"test-autogluon-image-1681570642-16bb\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681570642-16bb/source/sourcedir.tar.gz\",\"module_name\":\"training_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_SERVING=/opt/ml/input/data/serving\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALID=/opt/ml/input/data/valid\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 training_script.py\u001b[0m\n",
      "\u001b[34m2023-04-15 15:00:12,714 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mStarting AG\u001b[0m\n",
      "\u001b[34mArgs: Namespace(output_data_dir='/opt/ml/output/data', model_dir='/opt/ml/model', n_gpus='0', train_dir='/opt/ml/input/data/train', valid_dir='/opt/ml/input/data/valid', test_dir='/opt/ml/input/data/test', ag_config='/opt/ml/input/data/config', serving_script='/opt/ml/input/data/serving')\u001b[0m\n",
      "\u001b[34mUsing config-hpo.yaml\u001b[0m\n",
      "\u001b[34mRunning training job with the config:\u001b[0m\n",
      "\u001b[34m{\u001b[0m\n",
      "\u001b[34m'ag_fit_args':\u001b[0m\n",
      "\u001b[34m{'hyperparameter_tune_kwargs': 'auto',\n",
      "                 'hyperparameters': 'default',\n",
      "                 'num_bag_folds': 2,\n",
      "                 'num_bag_sets': 1,\n",
      "                 'num_stack_levels': 0,\n",
      "                 'presets': 'best_quality',\n",
      "                 'time_limit': 600,\n",
      "                 'use_bag_holdout': True}\u001b[0m\n",
      "\u001b[34m,\n",
      " 'ag_predictor_args':\u001b[0m\n",
      "\u001b[34m{'eval_metric': 'roc_auc',\n",
      "                       'label': 'target',\n",
      "                       'learner_kwargs': {'ignored_columns': ['customer_ID',\n",
      "                                                              'S_2']},\n",
      "                       'problem_type': 'binary'},\n",
      " 'feature_importance': False,\n",
      " 'leaderboard': True,\n",
      " 'num_gpus': 0,\n",
      " 'output_prediction_format': 'csv'}\u001b[0m\n",
      "\u001b[34mUsing train.csv\u001b[0m\n",
      "\u001b[34mUsing valid.csv\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mPresets specified: ['best_quality']\u001b[0m\n",
      "\u001b[34mWarning: hyperparameter tuning is currently experimental and may cause the process to hang.\u001b[0m\n",
      "\u001b[34mStack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=2, num_bag_sets=1\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ... Time limit = 600s\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.7.0\u001b[0m\n",
      "\u001b[34mPython Version:     3.9.16\u001b[0m\n",
      "\u001b[34mOperating System:   Linux\u001b[0m\n",
      "\u001b[34mPlatform Machine:   x86_64\u001b[0m\n",
      "\u001b[34mPlatform Version:   #1 SMP Tue Feb 14 21:50:23 UTC 2023\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    91000\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 46\u001b[0m\n",
      "\u001b[34mTuning Data Rows:    14000\u001b[0m\n",
      "\u001b[34mTuning Data Columns: 46\u001b[0m\n",
      "\u001b[34mLabel Column: target\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mSelected class <--> label mapping:  class 1 = 1, class 0 = 0\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mDropping user-specified ignored columns: ['customer_ID', 'S_2']\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34mAvailable Memory:                    30942.42 MB\u001b[0m\n",
      "\u001b[34mTrain Data (Original)  Memory Usage: 36.96 MB (0.1% of available memory)\u001b[0m\n",
      "\u001b[34mInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34mStage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34mNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\u001b[0m\n",
      "\u001b[34mStage 2 Generators:\u001b[0m\n",
      "\u001b[34mFitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34mStage 3 Generators:\u001b[0m\n",
      "\u001b[34mFitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34mStage 4 Generators:\u001b[0m\n",
      "\u001b[34mFitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34mTypes of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m('float', []) : 31 | ['CID_month', 'R_1', 'B_3', 'D_45', 'B_9', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', [])   : 13 | ['D_59', 'D_64', 'S_15', 'D_82', 'B_30', ...]\u001b[0m\n",
      "\u001b[34mTypes of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m('float', [])     : 31 | ['CID_month', 'R_1', 'B_3', 'D_45', 'B_9', ...]\u001b[0m\n",
      "\u001b[34m('int', [])       : 12 | ['D_59', 'D_64', 'S_15', 'D_82', 'B_30', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', ['bool']) :  1 | ['B_31']\u001b[0m\n",
      "\u001b[34m#0110.6s = Fit runtime\u001b[0m\n",
      "\u001b[34m44 features in original data used to generate 44 features in processed data.\u001b[0m\n",
      "\u001b[34mTrain Data (Processed) Memory Usage: 36.23 MB (0.1% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.64s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\u001b[0m\n",
      "\u001b[34m#011This metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\u001b[0m\n",
      "\u001b[34mTo change this, specify the eval_metric parameter of Predictor()\u001b[0m\n",
      "\u001b[34muse_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\u001b[0m\n",
      "\u001b[34mFitting 13 L1 models ...\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: KNeighborsUnif_BAG_L1 ... Tuning model for up to 41.49s of the 599.36s of remaining time.\u001b[0m\n",
      "\u001b[34mNo hyperparameter search space specified for KNeighborsUnif_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\u001b[0m\n",
      "\u001b[34mFitted model: KNeighborsUnif_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m0.9546#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m9.84s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: KNeighborsDist_BAG_L1 ... Tuning model for up to 41.49s of the 588.49s of remaining time.\u001b[0m\n",
      "\u001b[34mNo hyperparameter search space specified for KNeighborsDist_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\u001b[0m\n",
      "\u001b[34mFitted model: KNeighborsDist_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m0.9646#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0119.6s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 41.49s of the 578.6s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34mStopping HPO to satisfy time limit...\u001b[0m\n",
      "\u001b[34mFitted model: LightGBMXT_BAG_L1/T1 ...\u001b[0m\n",
      "\u001b[34m0.9771#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01139.64s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 41.49s of the 538.61s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34mStopping HPO to satisfy time limit...\u001b[0m\n",
      "\u001b[34mFitted model: LightGBM_BAG_L1/T1 ...\u001b[0m\n",
      "\u001b[34m0.984#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m37.62s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: RandomForestGini_BAG_L1 ... Tuning model for up to 41.49s of the 500.69s of remaining time.\u001b[0m\n",
      "\u001b[34mNo hyperparameter search space specified for RandomForestGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\u001b[0m\n",
      "\u001b[34mFitted model: RandomForestGini_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m0.9806#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01133.63s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: RandomForestEntr_BAG_L1 ... Tuning model for up to 41.49s of the 466.79s of remaining time.\u001b[0m\n",
      "\u001b[34mNo hyperparameter search space specified for RandomForestEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\u001b[0m\n",
      "\u001b[34mFitted model: RandomForestEntr_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m0.9818#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01138.91s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 41.49s of the 427.64s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34mStopping HPO to satisfy time limit...\u001b[0m\n",
      "\u001b[34mFitted model: CatBoost_BAG_L1/T1 ...\u001b[0m\n",
      "\u001b[34m0.9721#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01131.86s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: ExtraTreesGini_BAG_L1 ... Tuning model for up to 41.49s of the 395.49s of remaining time.\u001b[0m\n",
      "\u001b[34mNo hyperparameter search space specified for ExtraTreesGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\u001b[0m\n",
      "\u001b[34mFitted model: ExtraTreesGini_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m0.9882#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01110.47s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: ExtraTreesEntr_BAG_L1 ... Tuning model for up to 41.49s of the 384.77s of remaining time.\u001b[0m\n",
      "\u001b[34mNo hyperparameter search space specified for ExtraTreesEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\u001b[0m\n",
      "\u001b[34mFitted model: ExtraTreesEntr_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m0.9886#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01110.4s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 41.49s of the 374.13s of remaining time.\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetFastAI_BAG_L1/3ee9086c ...\u001b[0m\n",
      "\u001b[34m0.9341#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m34.42s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetFastAI_BAG_L1/c41a51fb ...\u001b[0m\n",
      "\u001b[34m0.8844#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m16.15s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetFastAI_BAG_L1/02221c4c ...\u001b[0m\n",
      "\u001b[34m0.9273#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m33.58s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetFastAI_BAG_L1/243488b4 ...\u001b[0m\n",
      "\u001b[34m0.9144#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m17.46s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetFastAI_BAG_L1/b4f637cc ...\u001b[0m\n",
      "\u001b[34m0.9202#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m21.26s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetFastAI_BAG_L1/62dee9d9 ...\u001b[0m\n",
      "\u001b[34m0.9189#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m17.09s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 41.49s of the 330.62s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34mStopping HPO to satisfy time limit...\u001b[0m\n",
      "\u001b[34mFitted model: XGBoost_BAG_L1/T1 ...\u001b[0m\n",
      "\u001b[34m0.9571#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m32.15s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mHyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 41.49s of the 298.18s of remaining time.\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetTorch_BAG_L1/fc6612ee ...\u001b[0m\n",
      "\u001b[34m0.9296#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m31.96s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetTorch_BAG_L1/18bfbdb1 ...\u001b[0m\n",
      "\u001b[34m0.9221#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m28.56s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetTorch_BAG_L1/753f88ef ...\u001b[0m\n",
      "\u001b[34m0.922#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m31.74s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitted model: NeuralNetTorch_BAG_L1/f33c7859 ...\u001b[0m\n",
      "\u001b[34m0.9178#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m32.33s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMLarge_BAG_L1 ... Training model for up to 41.49s of the 254.84s of remaining time.\u001b[0m\n",
      "\u001b[34mFitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m0.9205#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#01134.04s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m7.89s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34m[2023-04-15 15:06:53.001 algo-1:46 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-04-15 15:06:53.031 algo-1:46 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 197.31s of remaining time.\u001b[0m\n",
      "\u001b[34m0.924#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0114.09s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m0.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 406.83s ... Best model: \"WeightedEnsemble_L2\"\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34mUsing test.csv\u001b[0m\n",
      "\u001b[34mLoaded data from: /opt/ml/input/data/test/test.csv | Columns = 47 / 47 | Rows = 6000 -> 6000\u001b[0m\n",
      "\u001b[34mmodel  score_test  score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\u001b[0m\n",
      "\u001b[34m0                 XGBoost_BAG_L1/T1    0.927513   0.957133        0.055309       0.000266   32.149681                 0.055309                0.000266          32.149681            1       True         16\u001b[0m\n",
      "\u001b[34m1               WeightedEnsemble_L2    0.927401   0.924045        4.303354       0.006249  350.826091                 0.006709                0.002205           4.087272            2       True         22\u001b[0m\n",
      "\u001b[34m2                CatBoost_BAG_L1/T1    0.924664   0.972075        0.021871       0.000266   31.859967                 0.021871                0.000266          31.859967            1       True          7\u001b[0m\n",
      "\u001b[34m3              LightGBMLarge_BAG_L1    0.923597   0.920464        0.986366       7.893181   34.036524                 0.986366                7.893181          34.036524            1       True         21\u001b[0m\n",
      "\u001b[34m4              LightGBMXT_BAG_L1/T1    0.922463   0.977130        1.236538       0.000355   39.641350                 1.236538                0.000355          39.641350            1       True          3\u001b[0m\n",
      "\u001b[34m5                LightGBM_BAG_L1/T1    0.922200   0.984045        1.022988       0.000314   37.616228                 1.022988                0.000314          37.616228            1       True          4\u001b[0m\n",
      "\u001b[34m6           RandomForestEntr_BAG_L1    0.920549   0.981823        0.418509       0.000285   38.907831                 0.418509                0.000285          38.907831            1       True          6\u001b[0m\n",
      "\u001b[34m7   NeuralNetFastAI_BAG_L1/3ee9086c    0.920193   0.934145        0.168519       0.000445   34.416113                 0.168519                0.000445          34.416113            1       True         10\u001b[0m\n",
      "\u001b[34m8   NeuralNetFastAI_BAG_L1/02221c4c    0.919940   0.927266        0.107677       0.000996   33.576636                 0.107677                0.000996          33.576636            1       True         12\u001b[0m\n",
      "\u001b[34m9   NeuralNetFastAI_BAG_L1/b4f637cc    0.919639   0.920170        0.253192       0.000443   21.260780                 0.253192                0.000443          21.260780            1       True         14\u001b[0m\n",
      "\u001b[34m10   NeuralNetTorch_BAG_L1/18bfbdb1    0.919594   0.922053        0.174624       0.000426   28.564860                 0.174624                0.000426          28.564860            1       True         18\u001b[0m\n",
      "\u001b[34m11   NeuralNetTorch_BAG_L1/753f88ef    0.919052   0.921984        0.141687       0.000343   31.741066                 0.141687                0.000343          31.741066            1       True         19\u001b[0m\n",
      "\u001b[34m12          RandomForestGini_BAG_L1    0.918880   0.980556        0.466302       0.000279   33.628355                 0.466302                0.000279          33.628355            1       True          5\u001b[0m\n",
      "\u001b[34m13  NeuralNetFastAI_BAG_L1/62dee9d9    0.918551   0.918880        0.260915       0.000996   17.090566                 0.260915                0.000996          17.090566            1       True         15\u001b[0m\n",
      "\u001b[34m14            ExtraTreesEntr_BAG_L1    0.918226   0.988644        0.715290       0.000295   10.397632                 0.715290                0.000295          10.397632            1       True          9\u001b[0m\n",
      "\u001b[34m15   NeuralNetTorch_BAG_L1/f33c7859    0.917919   0.917836        0.171415       0.000377   32.329431                 0.171415                0.000377          32.329431            1       True         20\u001b[0m\n",
      "\u001b[34m16   NeuralNetTorch_BAG_L1/fc6612ee    0.917853   0.929578        0.136337       0.000440   31.962144                 0.136337                0.000440          31.962144            1       True         17\u001b[0m\n",
      "\u001b[34m17            ExtraTreesGini_BAG_L1    0.916705   0.988156        0.725225       0.000291   10.469591                 0.725225                0.000291          10.469591            1       True          8\u001b[0m\n",
      "\u001b[34m18  NeuralNetFastAI_BAG_L1/243488b4    0.913472   0.914433        0.062476       0.001270   17.460450                 0.062476                0.001270          17.460450            1       True         13\u001b[0m\n",
      "\u001b[34m19  NeuralNetFastAI_BAG_L1/c41a51fb    0.884307   0.884412        0.060446       0.000368   16.151304                 0.060446                0.000368          16.151304            1       True         11\u001b[0m\n",
      "\u001b[34m20            KNeighborsUnif_BAG_L1    0.839027   0.954580        0.693648       0.001037    9.844833                 0.693648                0.001037           9.844833            1       True          1\u001b[0m\n",
      "\u001b[34m21            KNeighborsDist_BAG_L1    0.838427   0.964628        0.702836       0.000305    9.597234                 0.702836                0.000305           9.597234            1       True          2\u001b[0m\n",
      "\u001b[34mSaving serving script\u001b[0m\n",
      "\u001b[34mUsing inference_script.py\u001b[0m\n",
      "\u001b[34m2023-04-15 15:07:17,989 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-04-15 15:07:17,989 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-04-15 15:07:17,990 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-04-15 15:07:26 Uploading - Uploading generated training model\n",
      "2023-04-15 15:10:17 Completed - Training job completed\n",
      "Training seconds: 720\n",
      "Billable seconds: 720\n"
     ]
    }
   ],
   "source": [
    "train_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"Final-Capstone-Data\", \"train.csv\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "valid_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"Final-Capstone-Data\", \"valid.csv\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "eval_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"Final-Capstone-Data\", \"test.csv\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-hpo.yaml\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "inference_script = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"scripts\", \"inference_script.py\"), bucket=bucket, key_prefix=s3_prefix\n",
    ")\n",
    "\n",
    "job_name = utils.unique_name_from_base(\"test-autogluon-image\")\n",
    "hpo_predictor = ag.fit(\n",
    "    {\n",
    "        \"config\": config_input,\n",
    "        \"train\": train_input,\n",
    "        \"valid\": valid_input,\n",
    "        \"test\": eval_input,\n",
    "        \"serving\": inference_script\n",
    "    },\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f122d6a2-d047-4170-9292-232fa0213772",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hpo_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da20b761-0c55-4c7f-a4d7-ea2d245ff7af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-004538843871/test-autogluon-image-1681570642-16bb/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Download the trained model saved in S3 (To be executed once)\n",
    "!aws s3 cp {ag.model_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa27d74e-41ab-4fd5-9894-35f9e2c01048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 555762994 Apr 15 15:10 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -alF model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4075022-f575-4509-84e9-e2f79157a19a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autogluon-serving-trained-model-1681572062-df69\n"
     ]
    }
   ],
   "source": [
    "# Upload the latest trained model to a desired path in S3\n",
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"autogluon-serving-trained-model\")\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72989a0e-b39b-4204-aab8-ec4584df46e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d19e7674-aa58-4cc8-9155-ac6bb62d91f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure for deployment and inferencing\n",
    "instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "model = AutoGluonNonRepackInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.7\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=instance_type,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"inference_script.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e441b019-7aee-4ac8-9761-09bbe0b4e219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating model with name: autogluon-inference-2023-04-15-15-22-54-164\n",
      "INFO:sagemaker:Creating endpoint-config with name autogluon-inference-2023-04-15-15-22-54-985\n",
      "INFO:sagemaker:Creating endpoint with name autogluon-inference-2023-04-15-15-22-54-985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "model.deploy(initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d500fd-820a-401d-9737-6fbd2979e6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autogluon-inference-2023-04-15-15-22-54-985'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print deployed latest endpoint details\n",
    "model.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15d12acc-951e-41bb-bfca-ece8b42b94de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "# Create a predictor for testing without Lambda\n",
    "predictor = AutoGluonRealtimePredictor(model.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa4f6748-7542-43b5-b99b-d11f4fc22751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Test data\n",
    "df_test = pd.read_csv(\"Final-Capstone-Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3064c9f7-851c-4571-a9f0-e386144ac678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on test data by removing columns not required\n",
    "preds = predictor.predict(df_test.drop(columns=[\"customer_ID\", \"S_2\", \"target\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "992227f1-73be-4521-9edb-9eeee373c97c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred  actual\n",
       "0     1       1\n",
       "1     1       1\n",
       "2     0       0\n",
       "3     1       1\n",
       "4     1       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine predicted and actual values in same Dataframe\n",
    "p = preds[[\"pred\"]]\n",
    "p = p.join(df_test[\"target\"]).rename(columns={\"target\": \"actual\"})\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bde57a33-43aa-4336-ad86-81f443efa1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4994/6000 are correct\n"
     ]
    }
   ],
   "source": [
    "# Print the accurate prediction count\n",
    "print(f\"{(p.pred==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "394276c4-3a3e-4f0c-a8fd-be4e1b0dd03f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354/1500 defaulters are correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"{p[(p['pred']==1) & (p['actual']==1)].shape[0]}/1500 defaulters are correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bce6550a-b8d2-471c-917f-42a958c3444f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3640/4500 non-defaulters are correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"{p[(p['pred']==0) & (p['actual']==0)].shape[0]}/4500 non-defaulters are correct\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
